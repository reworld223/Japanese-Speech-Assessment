{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "836aeccc-77fa-42cf-9753-6153768dc811",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-14 13:56:10,917 - modelscope - INFO - PyTorch version 2.2.1+cu118 Found.\n",
      "2024-05-14 13:56:10,918 - modelscope - INFO - Loading ast index from /root/.cache/modelscope/ast_indexer\n",
      "2024-05-14 13:56:10,941 - modelscope - INFO - Loading done! Current index file version is 1.13.3, with md5 c0ac150aa6e7febf5244e661bd5f3e7d and a total number of 972 components indexed\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion succeeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-14 13:56:31,576 - modelscope - WARNING - Model revision not specified, use revision: v1.0.2\n",
      "2024-05-14 13:56:32,086 - modelscope - INFO - initiate model from /root/.cache/modelscope/hub/damo/speech_frcrn_ans_cirm_16k\n",
      "2024-05-14 13:56:32,087 - modelscope - INFO - initiate model from location /root/.cache/modelscope/hub/damo/speech_frcrn_ans_cirm_16k.\n",
      "2024-05-14 13:56:32,088 - modelscope - INFO - initialize model from /root/.cache/modelscope/hub/damo/speech_frcrn_ans_cirm_16k\n",
      "2024-05-14 13:56:32,319 - modelscope - WARNING - No preprocessor field found in cfg.\n",
      "2024-05-14 13:56:32,319 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
      "2024-05-14 13:56:32,320 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': '/root/.cache/modelscope/hub/damo/speech_frcrn_ans_cirm_16k'}. trying to build by task and model information.\n",
      "2024-05-14 13:56:32,320 - modelscope - WARNING - No preprocessor key ('speech_frcrn_ans_cirm_16k', 'acoustic-noise-suppression') found in PREPROCESSOR_MAP, skip building preprocessor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:(1, 9747)\n",
      "inputs after padding:(1, 16000)\n",
      "Average Energy: 0.37866303\n",
      "Maximum Amplitude: 0.17047119\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8da6372e510e4d049ae9e5a7bff7e288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Beam search progress:: 100% 1/1 [00:00<00:00, 19.28sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asr text:  あなた。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54960ccbb8cd49669d788fce430ebc9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most similar word:  あなた highest_similarity:  1.0\n",
      "score:  100\n",
      "100 あなた\n"
     ]
    }
   ],
   "source": [
    "import scoringModule\n",
    "\n",
    "result, text = scoringModule.scoring('./audio/あなた.mp3')\n",
    "print(result, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "923b57d9-0ed3-44fd-b404-3d59a9d7e962",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import HubertForCTC, Wav2Vec2Processor, AutoTokenizer\n",
    "import torchaudio\n",
    "processor = Wav2Vec2Processor.from_pretrained('TKU410410103/hubert-base-japanese-asr')\n",
    "hubert = HubertForCTC.from_pretrained('../HubertForCTC/local_dataset/local_ASR/checkpoint-450')\n",
    "\n",
    "def process_waveforms(batch='./audio/あのひと.mp3'):\n",
    "    waveform, sample_rate = torchaudio.load(batch)\n",
    "    if sample_rate != 16000:\n",
    "        resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)\n",
    "        waveform = resampler(waveform)\n",
    "    # 如果 waveform 是雙聲道，需要轉單聲道。\n",
    "    if waveform.size(0) > 1:\n",
    "        waveform = waveform.mean(dim=0)\n",
    "    # 讓 waveform的維度正確\n",
    "    if waveform.ndim > 1:\n",
    "        waveform = waveform.squeeze()\n",
    "    return waveform\n",
    "waveform=process_waveforms()\n",
    "processed_audios = processor(waveform,\n",
    "                        sampling_rate=16000,\n",
    "                        return_tensors=\"pt\",\n",
    "                        padding=True,\n",
    "                        truncation=True,\n",
    "                        max_length=160000)\n",
    "outputs = hubert(**processed_audios)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5d67a85-c889-4b96-b694-e042f865a37f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'あのひと'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Assuming outputs.logits is the tensor of logits from your model\n",
    "predicted_ids = torch.argmax(outputs.logits, dim=-1)  # Get the most likely token index at each timestep\n",
    "\n",
    "# Flatten the tensor to a 1D list of integers, in case it's multidimensional\n",
    "predicted_ids = predicted_ids.view(-1).tolist()\n",
    "\n",
    "# Decode the list of token IDs\n",
    "decoded_output = processor.decode(predicted_ids)\n",
    "decoded_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "24350084-aec3-4ff7-9e6d-ca9484ed3aa3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-19 06:56:10,499 - modelscope - INFO - PyTorch version 2.2.1+cu118 Found.\n",
      "2024-04-19 06:56:10,501 - modelscope - INFO - Loading ast index from /root/.cache/modelscope/ast_indexer\n",
      "2024-04-19 06:56:10,623 - modelscope - INFO - Loading done! Current index file version is 1.13.3, with md5 c0ac150aa6e7febf5244e661bd5f3e7d and a total number of 972 components indexed\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "2024-04-19 06:56:16,122 - modelscope - WARNING - Model revision not specified, use revision: v1.0.2\n",
      "2024-04-19 06:56:16,635 - modelscope - INFO - initiate model from /root/.cache/modelscope/hub/damo/speech_frcrn_ans_cirm_16k\n",
      "2024-04-19 06:56:16,635 - modelscope - INFO - initiate model from location /root/.cache/modelscope/hub/damo/speech_frcrn_ans_cirm_16k.\n",
      "2024-04-19 06:56:16,636 - modelscope - INFO - initialize model from /root/.cache/modelscope/hub/damo/speech_frcrn_ans_cirm_16k\n",
      "2024-04-19 06:56:17,002 - modelscope - WARNING - No preprocessor field found in cfg.\n",
      "2024-04-19 06:56:17,003 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
      "2024-04-19 06:56:17,003 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': '/root/.cache/modelscope/hub/damo/speech_frcrn_ans_cirm_16k'}. trying to build by task and model information.\n",
      "2024-04-19 06:56:17,004 - modelscope - WARNING - No preprocessor key ('speech_frcrn_ans_cirm_16k', 'acoustic-noise-suppression') found in PREPROCESSOR_MAP, skip building preprocessor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:(1, 14364)\n",
      "inputs after padding:(1, 16000)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f50cca486c8c4ed1a32530e91de6e216",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scoringModule_onlyHubert\n",
    "\n",
    "scoringModule_onlyHubert.scoring('./audio/あのひと.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676b92e5-24e5-4f88-9281-5ec85344117f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
