{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7bc7de4-5ff2-4419-a3a1-ce3945a88b97",
   "metadata": {
    "tags": []
   },
   "source": [
    "# wav2vec2 base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e86907d4-2acd-4410-852d-b7a8d11beb94",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e68958c9871444ed8e2a686b7dfa2fc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/2.12k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74a8108abe05402eb69ef1315146999a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/378M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Wav2Vec2ForCTC(\n",
       "  (wav2vec2): Wav2Vec2Model(\n",
       "    (feature_extractor): Wav2Vec2FeatureEncoder(\n",
       "      (conv_layers): ModuleList(\n",
       "        (0): Wav2Vec2GroupNormConvLayer(\n",
       "          (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)\n",
       "          (activation): GELUActivation()\n",
       "          (layer_norm): GroupNorm(512, 512, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (1-4): 4 x Wav2Vec2NoLayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (5-6): 2 x Wav2Vec2NoLayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (feature_projection): Wav2Vec2FeatureProjection(\n",
       "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (projection): Linear(in_features=512, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): Wav2Vec2Encoder(\n",
       "      (pos_conv_embed): Wav2Vec2PositionalConvEmbedding(\n",
       "        (conv): ParametrizedConv1d(\n",
       "          768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16\n",
       "          (parametrizations): ModuleDict(\n",
       "            (weight): ParametrizationList(\n",
       "              (0): _WeightNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (padding): Wav2Vec2SamePadLayer()\n",
       "        (activation): GELUActivation()\n",
       "      )\n",
       "      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x Wav2Vec2EncoderLayer(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (lm_head): Linear(in_features=768, out_features=122, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Wav2Vec2Processor\n",
    "from transformers import Wav2Vec2ForCTC\n",
    "\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"TKU410410103/wav2vec2-base-japanese-asr\")\n",
    "\n",
    "model = Wav2Vec2ForCTC.from_pretrained('TKU410410103/wav2vec2-base-japanese-asr')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a7b8530-7943-4f51-981d-7514556ed5dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Wav2Vec2ForCTC(\n",
       "  (wav2vec2): Wav2Vec2Model(\n",
       "    (feature_extractor): Wav2Vec2FeatureEncoder(\n",
       "      (conv_layers): ModuleList(\n",
       "        (0): Wav2Vec2GroupNormConvLayer(\n",
       "          (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)\n",
       "          (activation): GELUActivation()\n",
       "          (layer_norm): GroupNorm(512, 512, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (1-4): 4 x Wav2Vec2NoLayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (5-6): 2 x Wav2Vec2NoLayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (feature_projection): Wav2Vec2FeatureProjection(\n",
       "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (projection): Linear(in_features=512, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): Wav2Vec2Encoder(\n",
       "      (pos_conv_embed): Wav2Vec2PositionalConvEmbedding(\n",
       "        (conv): ParametrizedConv1d(\n",
       "          768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16\n",
       "          (parametrizations): ModuleDict(\n",
       "            (weight): ParametrizationList(\n",
       "              (0): _WeightNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (padding): Wav2Vec2SamePadLayer()\n",
       "        (activation): GELUActivation()\n",
       "      )\n",
       "      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x Wav2Vec2EncoderLayer(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (lm_head): Linear(in_features=768, out_features=122, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed418a2-d081-4497-8d65-aaa80cae82f4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Common Voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08046d9e-1d2f-4adc-814d-fb71e29d616d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/datasets/load.py:1454: FutureWarning: The repository for mozilla-foundation/common_voice_11_0 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mozilla-foundation/common_voice_11_0\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "test_dataset = load_dataset('mozilla-foundation/common_voice_11_0', 'ja', split='test')\n",
    "\n",
    "remove_columns = [col for col in test_dataset.column_names if col not in ['audio', 'sentence']]\n",
    "\n",
    "test_dataset = test_dataset.remove_columns(remove_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53afdae5-1d9e-40cf-a0e7-7bd2933e6b4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def process_waveforms(batch):\n",
    "    speech_arrays = []\n",
    "    sampling_rates = []\n",
    "\n",
    "    for audio_path in batch['audio']:\n",
    "        speech_array, _ = torchaudio.load(audio_path['path'])\n",
    "        speech_array_resampled = librosa.resample(np.asarray(speech_array[0].numpy()), orig_sr=48000, target_sr=16000)\n",
    "        speech_arrays.append(speech_array_resampled)\n",
    "        sampling_rates.append(16000)\n",
    "\n",
    "    batch[\"array\"] = speech_arrays\n",
    "    batch[\"sampling_rate\"] = sampling_rates\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17fa24f1-44a6-4291-9069-f6f28a88ae6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_45664/2471734099.py:14: DeprecationWarning: Call to deprecated method setMode. (Old API will be removed in v3.0.) -- Deprecated since version 2.1.\n",
      "  kakasi.setMode(\"J\",\"H\")\n",
      "/tmp/ipykernel_45664/2471734099.py:15: DeprecationWarning: Call to deprecated method setMode. (Old API will be removed in v3.0.) -- Deprecated since version 2.1.\n",
      "  kakasi.setMode(\"K\",\"H\")\n",
      "/tmp/ipykernel_45664/2471734099.py:16: DeprecationWarning: Call to deprecated method setMode. (Old API will be removed in v3.0.) -- Deprecated since version 2.1.\n",
      "  kakasi.setMode(\"r\",\"Hepburn\")\n",
      "/tmp/ipykernel_45664/2471734099.py:17: DeprecationWarning: Call to deprecated method getConverter. (Old API will be removed in v3.0.) -- Deprecated since version 2.1.\n",
      "  conv = kakasi.getConverter()\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import MeCab\n",
    "import pykakasi\n",
    "\n",
    "CHARS_TO_IGNORE = [\",\", \"?\", \"¿\", \".\", \"!\", \"¡\", \";\", \"；\", \":\", '\"\"', \"%\", '\"', \"�\", \"ʿ\", \"·\", \"჻\", \"~\", \"՞\",\n",
    "          \"؟\", \"،\", \"।\", \"॥\", \"«\", \"»\", \"„\", \"“\", \"”\", \"「\", \"」\", \"‘\", \"’\", \"《\", \"》\", \"(\", \")\", \"[\", \"]\",\n",
    "          \"{\", \"}\", \"=\", \"`\", \"_\", \"+\", \"<\", \">\", \"…\", \"–\", \"°\", \"´\", \"ʾ\", \"‹\", \"›\", \"©\", \"®\", \"—\", \"→\", \"。\",\n",
    "          \"、\", \"﹂\", \"﹁\", \"‧\", \"～\", \"﹏\", \"，\", \"｛\", \"｝\", \"（\", \"）\", \"［\", \"］\", \"【\", \"】\", \"‥\", \"〽\",\n",
    "          \"『\", \"』\", \"〝\", \"〟\", \"⟨\", \"⟩\", \"〜\", \"：\", \"！\", \"？\", \"♪\", \"؛\", \"/\", \"\\\\\", \"º\", \"−\", \"^\", \"'\", \"ʻ\", \"ˆ\"]\n",
    "chars_to_ignore_regex = f\"[{re.escape(''.join(CHARS_TO_IGNORE))}]\"\n",
    "\n",
    "wakati = MeCab.Tagger(\"-Owakati\")\n",
    "kakasi = pykakasi.kakasi()\n",
    "kakasi.setMode(\"J\",\"H\")\n",
    "kakasi.setMode(\"K\",\"H\")\n",
    "kakasi.setMode(\"r\",\"Hepburn\")\n",
    "conv = kakasi.getConverter()\n",
    "\n",
    "def prepare_char(batch):\n",
    "    batch[\"sentence\"] = conv.do(wakati.parse(batch[\"sentence\"]).strip())\n",
    "    batch[\"sentence\"] = re.sub(chars_to_ignore_regex,'', batch[\"sentence\"]).strip()\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "537b0548-5a07-48ab-bb32-f15ccde89e25",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/dill/_dill.py:414: PicklingWarning: Cannot locate reference to <enum '_TYPE'>.\n",
      "  StockPickler.save(self, obj, save_persistent_id)\n",
      "/usr/local/lib/python3.10/dist-packages/dill/_dill.py:414: PicklingWarning: Cannot pickle <enum '_TYPE'>: pykakasi.kakasi._TYPE has recursive self-references that trigger a RecursionError.\n",
      "  StockPickler.save(self, obj, save_persistent_id)\n",
      "Parameter 'function'=<function prepare_char at 0x7fe743e15870> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cdc9fe5ddab4ebe88c791c24ae60639",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/4604 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_45664/2471734099.py:20: DeprecationWarning: Call to deprecated method do. (Old API will be removed in v3.0.) -- Deprecated since version 2.1.\n",
      "  batch[\"sentence\"] = conv.do(wakati.parse(batch[\"sentence\"]).strip())\n",
      "/tmp/ipykernel_45664/2471734099.py:20: DeprecationWarning: Call to deprecated method do. (Old API will be removed in v3.0.) -- Deprecated since version 2.1.\n",
      "  batch[\"sentence\"] = conv.do(wakati.parse(batch[\"sentence\"]).strip())\n",
      "/tmp/ipykernel_45664/2471734099.py:20: DeprecationWarning: Call to deprecated method do. (Old API will be removed in v3.0.) -- Deprecated since version 2.1.\n",
      "  batch[\"sentence\"] = conv.do(wakati.parse(batch[\"sentence\"]).strip())\n",
      "/tmp/ipykernel_45664/2471734099.py:20: DeprecationWarning: Call to deprecated method do. (Old API will be removed in v3.0.) -- Deprecated since version 2.1.\n",
      "  batch[\"sentence\"] = conv.do(wakati.parse(batch[\"sentence\"]).strip())\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['audio', 'sentence', 'array', 'sampling_rate'],\n",
       "    num_rows: 4604\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resampled_eval_dataset = test_dataset.map(process_waveforms, batched=True, batch_size=50, num_proc=4)\n",
    "eval_dataset = resampled_eval_dataset.map(prepare_char, num_proc=4)\n",
    "eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c77f27e-0b74-4115-b288-aa152c3a784f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff9da697f67348b8945590a6bd05c329",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4604 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER: 14.177284%\n",
      "CER: 6.462501%\n"
     ]
    }
   ],
   "source": [
    "from evaluate import load\n",
    "\n",
    "wer = load(\"wer\")\n",
    "cer = load(\"cer\")\n",
    "\n",
    "def evaluate(batch):\n",
    "    inputs = processor(batch[\"array\"], sampling_rate=16_000, return_tensors=\"pt\", padding=True)\n",
    "    with torch.no_grad():\n",
    "        logits = model(inputs.input_values.to(device), attention_mask=inputs.attention_mask.to(device)).logits\n",
    "    pred_ids = torch.argmax(logits, dim=-1)\n",
    "    batch[\"pred_strings\"] = processor.batch_decode(pred_ids)\n",
    "    return batch\n",
    "\n",
    "columns_to_remove = [column for column in eval_dataset.column_names if column != \"sentence\"]\n",
    "batch_size = 16\n",
    "result = eval_dataset.map(evaluate, remove_columns=columns_to_remove, batched=True, batch_size=batch_size)\n",
    "\n",
    "wer_result = wer.compute(predictions=result[\"pred_strings\"], references=result[\"sentence\"])\n",
    "cer_result = cer.compute(predictions=result[\"pred_strings\"], references=result[\"sentence\"])\n",
    "\n",
    "print(\"WER: {:2f}%\".format(100 * wer_result))\n",
    "print(\"CER: {:2f}%\".format(100 * cer_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d34c3f-bcfb-474a-b9b6-930992ad0e2c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Reazon Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ee28fe4-bb26-488c-8e6d-b75d7b5b43a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/reazon-research--reazonspeech/e16d1ee2aae813b6ea960f564f4dc8481f58bfa6074be491eb4a6ddde66330bb (last modified on Sun Mar 24 05:42:58 2024) since it couldn't be found locally at reazon-research/reazonspeech, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "860d941b358c4593be3f9adceb8c76f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/521k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "029cd5f175fb4a0aab584b0a272a5beb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/605M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1ab1438d7db47288d1bcdf61e027efd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"reazon-research/reazonspeech\", \"tiny\", trust_remote_code=True) # tiny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58d938c5-4fcd-4c6b-aa13-cd43b7300766",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['name', 'audio', 'transcription'],\n",
       "    num_rows: 5323\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = ds['train']\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3df53fcc-48ca-4e16-b110-cd842cbf8929",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_45664/1574564692.py:14: DeprecationWarning: Call to deprecated method setMode. (Old API will be removed in v3.0.) -- Deprecated since version 2.1.\n",
      "  kakasi.setMode(\"J\",\"H\")\n",
      "/tmp/ipykernel_45664/1574564692.py:15: DeprecationWarning: Call to deprecated method setMode. (Old API will be removed in v3.0.) -- Deprecated since version 2.1.\n",
      "  kakasi.setMode(\"K\",\"H\")\n",
      "/tmp/ipykernel_45664/1574564692.py:16: DeprecationWarning: Call to deprecated method setMode. (Old API will be removed in v3.0.) -- Deprecated since version 2.1.\n",
      "  kakasi.setMode(\"r\",\"Hepburn\")\n",
      "/tmp/ipykernel_45664/1574564692.py:17: DeprecationWarning: Call to deprecated method getConverter. (Old API will be removed in v3.0.) -- Deprecated since version 2.1.\n",
      "  conv = kakasi.getConverter()\n",
      "/usr/local/lib/python3.10/dist-packages/dill/_dill.py:414: PicklingWarning: Cannot locate reference to <enum '_TYPE'>.\n",
      "  StockPickler.save(self, obj, save_persistent_id)\n",
      "/usr/local/lib/python3.10/dist-packages/dill/_dill.py:414: PicklingWarning: Cannot pickle <enum '_TYPE'>: pykakasi.kakasi._TYPE has recursive self-references that trigger a RecursionError.\n",
      "  StockPickler.save(self, obj, save_persistent_id)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ae00634f611474d8a076bbc2e4dad99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/5323 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_45664/1574564692.py:20: DeprecationWarning: Call to deprecated method do. (Old API will be removed in v3.0.) -- Deprecated since version 2.1.\n",
      "  batch[\"transcription\"] = conv.do(wakati.parse(batch[\"transcription\"]).strip())\n",
      "/tmp/ipykernel_45664/1574564692.py:20: DeprecationWarning: Call to deprecated method do. (Old API will be removed in v3.0.) -- Deprecated since version 2.1.\n",
      "  batch[\"transcription\"] = conv.do(wakati.parse(batch[\"transcription\"]).strip())\n",
      "/tmp/ipykernel_45664/1574564692.py:20: DeprecationWarning: Call to deprecated method do. (Old API will be removed in v3.0.) -- Deprecated since version 2.1.\n",
      "  batch[\"transcription\"] = conv.do(wakati.parse(batch[\"transcription\"]).strip())\n",
      "/tmp/ipykernel_45664/1574564692.py:20: DeprecationWarning: Call to deprecated method do. (Old API will be removed in v3.0.) -- Deprecated since version 2.1.\n",
      "  batch[\"transcription\"] = conv.do(wakati.parse(batch[\"transcription\"]).strip())\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import MeCab\n",
    "import pykakasi\n",
    "\n",
    "CHARS_TO_IGNORE = [\",\", \"?\", \"¿\", \".\", \"!\", \"¡\", \";\", \"；\", \":\", '\"\"', \"%\", '\"', \"�\", \"ʿ\", \"·\", \"჻\", \"~\", \"՞\",\n",
    "          \"؟\", \"،\", \"।\", \"॥\", \"«\", \"»\", \"„\", \"“\", \"”\", \"「\", \"」\", \"‘\", \"’\", \"《\", \"》\", \"(\", \")\", \"[\", \"]\",\n",
    "          \"{\", \"}\", \"=\", \"`\", \"_\", \"+\", \"<\", \">\", \"…\", \"–\", \"°\", \"´\", \"ʾ\", \"‹\", \"›\", \"©\", \"®\", \"—\", \"→\", \"。\",\n",
    "          \"、\", \"﹂\", \"﹁\", \"‧\", \"～\", \"﹏\", \"，\", \"｛\", \"｝\", \"（\", \"）\", \"［\", \"］\", \"【\", \"】\", \"‥\", \"〽\",\n",
    "          \"『\", \"』\", \"〝\", \"〟\", \"⟨\", \"⟩\", \"〜\", \"：\", \"！\", \"？\", \"♪\", \"؛\", \"/\", \"\\\\\", \"º\", \"−\", \"^\", \"'\", \"ʻ\", \"ˆ\"]\n",
    "chars_to_ignore_regex = f\"[{re.escape(''.join(CHARS_TO_IGNORE))}]\"\n",
    "\n",
    "wakati = MeCab.Tagger(\"-Owakati\")\n",
    "kakasi = pykakasi.kakasi()\n",
    "kakasi.setMode(\"J\",\"H\")\n",
    "kakasi.setMode(\"K\",\"H\")\n",
    "kakasi.setMode(\"r\",\"Hepburn\")\n",
    "conv = kakasi.getConverter()\n",
    "\n",
    "def prepare_char(batch):\n",
    "    batch[\"transcription\"] = conv.do(wakati.parse(batch[\"transcription\"]).strip())\n",
    "    batch[\"transcription\"] = re.sub(chars_to_ignore_regex,'', batch[\"transcription\"]).strip()\n",
    "    return batch\n",
    "\n",
    "encoded_ds = ds.map(prepare_char, num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7845607-1f6b-4c76-8d1f-b84e80e620ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16a919287b8d45e38c372186690bd0eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5323 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER: 40.864413%\n",
      "CER: 29.367348%\n"
     ]
    }
   ],
   "source": [
    "from evaluate import load\n",
    "\n",
    "wer = load(\"wer\")\n",
    "cer = load(\"cer\")\n",
    "\n",
    "def evaluate(batch):\n",
    "    pred_strings = []\n",
    "    for audio in batch[\"audio\"]:\n",
    "        inputs = processor(audio[\"array\"], sampling_rate=16000, return_tensors=\"pt\", padding=True)\n",
    "        inputs = inputs.to(device)\n",
    "        with torch.no_grad():\n",
    "            logits = model(inputs.input_values).logits\n",
    "        pred_ids = torch.argmax(logits, dim=-1)\n",
    "\n",
    "        pred_ids[pred_ids == -100] = processor.tokenizer.pad_token_id\n",
    "\n",
    "        pred_string = processor.batch_decode(pred_ids)\n",
    "\n",
    "        pred_strings.extend(pred_string)\n",
    "\n",
    "    batch[\"pred_strings\"] = pred_strings\n",
    "    return batch\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "columns_to_remove = [column for column in encoded_ds.column_names if column != \"transcription\"]\n",
    "result = encoded_ds.map(evaluate, remove_columns=columns_to_remove, batched=True, batch_size=batch_size)\n",
    "\n",
    "wer_result = wer.compute(predictions=result[\"pred_strings\"], references=result[\"transcription\"])\n",
    "cer_result = cer.compute(predictions=result[\"pred_strings\"], references=result[\"transcription\"])\n",
    "\n",
    "print(\"WER: {:2f}%\".format(100 * wer_result))\n",
    "print(\"CER: {:2f}%\".format(100 * cer_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2284f0d-60f9-40d2-b79f-7511ab120f07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
